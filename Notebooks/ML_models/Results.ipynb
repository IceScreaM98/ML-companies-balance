{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ML models results overview"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Liberie varie da installare"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inclusione delle librerie utilizzate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "# Change plot output format\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "from pandas import ExcelWriter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Variabili di gestione files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Path of the directory containing .pkl file of the different ML models results, can be changed\n",
    "DATASET_PATH = r\"C:\\Users\\Andre\\OneDrive - Università degli Studi di Parma\\Tirocinio\\ML_models\\ML_model_experiments.pkl\"\n",
    "\n",
    "# True = export summary file in the OUTPUT_PATH\n",
    "to_export = True\n",
    "\n",
    "# Content of the exported document, possible values are 'Rankings' or 'Description',\n",
    "# the default value is 'Description'\n",
    "export_content = \"Description\"\n",
    "\n",
    "# Path of the output file report, can be changed\n",
    "OUTPUT_PATH = r\"C:\\Users\\Andre\\OneDrive - Università degli Studi di Parma\\Tirocinio\\ML_models\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Leggo il dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(DATASET_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rimuovo eventuali esperimenti duplicati"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset.drop_duplicates(subset=[ 'Accuracy - test',\n",
    "                                 'Precision - test',\n",
    "                                 'Specificity - test',\n",
    "                                 'Recall - test',\n",
    "                                 'F1-score - test',\n",
    "                                 'MCC - test',\n",
    "                                 'AUC - test'],\n",
    "                        keep='last',\n",
    "                        inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mostro i risultati ordinati per F1-score sul test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset.sort_values(by=['F1-score - test'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dataset = dataset[dataset[\"Dataset - train/test\"].str.contains('history3', regex=False)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset[dataset[\"Dataset - train/test\"].str.contains('CE|SP', regex=True)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot model type"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dataset list in order to export a unique excel file with multiple sheets\n",
    "dataset_list = []\n",
    "keys_order = [\"Decision Tree\", \"Random Forest\", \"Gradient Boosting\", \"Logistic regression\", \"SVC Classifier\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keep_columns = [\"Model type\", \"Accuracy - test\", 'Specificity - test', \"Precision - test\",\n",
    "                \"Recall - test\", \"F1-score - test\", \"AUC - test\"]\n",
    "if export_content == \"Rankings\":\n",
    "    d1 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Model type\"]).mean().sort_values(by=['F1-score - test'], ascending=False)\n",
    "else:\n",
    "    d1 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Model type\"]).agg([np.mean, np.std])\n",
    "dataset_list.append(d1.round(2))\n",
    "d1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Model type\", y=\"Accuracy - test\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], order=keys_order)\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Accuracy_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Model type\", y=\"Specificity - test\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], order=keys_order)\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Specificity_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Model type\", y=\"Precision - test\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], order=keys_order)\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Precision_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Model type\", y=\"Recall - test\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], order=keys_order)\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Recall_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Model type\", y=\"F1-score - test\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], order=keys_order)\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/F1-score_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Model type\", y=\"MCC - test\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], order=keys_order)\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/MCC_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Model type\", y=\"AUC - test\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], order=keys_order)\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/AUC_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = pd.melt(dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], id_vars=['Model type'],\n",
    "                  value_vars=['Accuracy - test', 'Specificity - test', 'Precision - test', 'Recall - test', 'F1-score - test', 'MCC - test', 'AUC - test'],\n",
    "                  var_name='Metric')\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Model type\", y=\"value\", hue=\"Metric\", data=results, orient=\"v\", order=keys_order)\n",
    "plt.legend(loc='lower left')\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Metrics_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot dataset train/test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keep_columns = [\"Dataset - train/test\", \"Accuracy - test\", 'Specificity - test', \"Precision - test\",\n",
    "                \"Recall - test\", \"F1-score - test\", \"MCC - test\", \"AUC - test\"]\n",
    "if export_content == \"Rankings\":\n",
    "    d2 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Dataset - train/test\"]).mean().sort_values(by=['F1-score - test'], ascending=False)\n",
    "else:\n",
    "    d2 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Dataset - train/test\"]).agg([np.mean, np.std])\n",
    "dataset_list.append(d2.round(2))\n",
    "d2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_order = sorted(dataset[\"Dataset - train/test\"].drop_duplicates())\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Accuracy - test\", y=\"Dataset - train/test\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], orient=\"h\", order=dataset_order)\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Dataset_accuracy_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Specificity - test\", y=\"Dataset - train/test\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], orient=\"h\", order=dataset_order)\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Dataset_specificity_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Precision - test\", y=\"Dataset - train/test\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], orient=\"h\", order=dataset_order)\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Dataset_precision_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Recall - test\", y=\"Dataset - train/test\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], orient=\"h\", order=dataset_order)\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Dataset_recall_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"MCC - test\", y=\"Dataset - train/test\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], orient=\"h\", order=dataset_order)\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Dataset_MCC_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"AUC - test\", y=\"Dataset - train/test\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], orient=\"h\", order=dataset_order)\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Dataset_AUC_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"F1-score - test\", y=\"Dataset - train/test\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], orient=\"h\", order=dataset_order)\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Dataset_F1-score_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = pd.melt(dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], id_vars=['Dataset - train/test'],\n",
    "                  value_vars=['Accuracy - test', 'Specificity - test', 'Precision - test', 'Recall - test', 'F1-score - test', 'MCC - test', 'AUC - test'],\n",
    "                  var_name='Metric')\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 20))\n",
    "sns.barplot(x=\"value\", y=\"Dataset - train/test\", hue=\"Metric\", data=results, orient=\"h\", order=dataset_order)\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "# Change y labels in order to have more space for the graph part\n",
    "ylabels = list(dict.fromkeys(results[\"Dataset - train/test\"].to_list()))\n",
    "ylabels_new = [label.replace('filtered_active_bankruptcy_', 'filtered_active_bankruptcy_\\n') for label in ylabels]\n",
    "plt.yticks(np.arange(len(ylabels_new)), ylabels_new)\n",
    "\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Dataset_metrics_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Divide datasets in four categories\n",
    "def dataset_mapping(dataset_name):\n",
    "    if \"history\" in dataset_name:\n",
    "        return \"Datasets based on temporal series\"\n",
    "    elif \"raw_full\" in dataset_name:\n",
    "        return \"Datasets based on all raw values\"\n",
    "    elif \"raw\" in dataset_name:\n",
    "        return \"Datasets based on a subset of raw values\"\n",
    "    elif \"small\" in dataset_name:\n",
    "        return \"Datasets based only on financial estimators\"\n",
    "    elif \"big\" in dataset_name:\n",
    "        return \"Datasets based only on financial estimators\"\n",
    "    else:\n",
    "        return \"Other type of dataset\"\n",
    "\n",
    "# Apply mapping\n",
    "results[\"Dataset - train/test\"] = results[\"Dataset - train/test\"].apply(dataset_mapping)\n",
    "dataset_order = [\"Datasets based only on financial estimators\", \"Datasets based on a subset of raw values\",\n",
    "                  \"Datasets based on all raw values\", \"Datasets based on temporal series\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"value\", y=\"Dataset - train/test\", hue=\"Metric\", data=results, orient=\"h\", order=dataset_order)\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Dataset_categories_metrics_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot model type & dataset train/test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keep_columns = [\"Model type\", \"Dataset - train/test\", \"Accuracy - test\", 'Specificity - test',\n",
    "                \"Precision - test\", \"Recall - test\", \"F1-score - test\", \"MCC - test\", \"AUC - test\"]\n",
    "if export_content == \"Rankings\":\n",
    "    d3 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Model type\", \"Dataset - train/test\"]).mean().sort_values(by=['F1-score - test'], ascending=False)\n",
    "else:\n",
    "    d3 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Model type\", \"Dataset - train/test\"]).agg([np.mean, np.std])\n",
    "dataset_list.append(d3.round(2))\n",
    "d3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot number of components"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keep_columns = [\"Number of features\", \"Accuracy - test\", 'Specificity - test', \"Precision - test\",\n",
    "                \"Recall - test\", \"F1-score - test\", \"MCC - test\", \"AUC - test\"]\n",
    "if export_content == \"Rankings\":\n",
    "    d4 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Number of features\"]).mean().sort_values(by=['F1-score - test'], ascending=False)\n",
    "else:\n",
    "    d4 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Number of features\"]).agg([np.mean, np.std])\n",
    "dataset_list.append(d4.round(2))\n",
    "d4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = pd.melt(dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], id_vars=['Number of features'],\n",
    "                  value_vars=['Accuracy - test', 'Specificity - test', 'Precision - test', 'Recall - test', 'F1-score - test', 'MCC - test', 'AUC - test'],\n",
    "                  var_name='Metric')\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Number of features\", y=\"value\", hue=\"Metric\", data=results, orient=\"v\")\n",
    "plt.legend(loc='lower left')\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Number_of_features_metrics.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot model type & number of components"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keep_columns = [\"Model type\", \"Number of features\", \"Accuracy - test\", 'Specificity - test',\n",
    "                \"Precision - test\", \"Recall - test\", \"F1-score - test\", \"MCC - test\", \"AUC - test\"]\n",
    "if export_content == \"Rankings\":\n",
    "    d5 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Model type\", \"Number of features\"]).mean().sort_values(by=['F1-score - test'], ascending=False)\n",
    "else:\n",
    "    d5 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Model type\", \"Number of features\"]).agg([np.mean, np.std])\n",
    "dataset_list.append(d5.round(2))\n",
    "d5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot dimensionality reduction technique & number of components"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keep_columns = [\"Dimensionality reduction technique\", \"Number of features\", \"Accuracy - test\", 'Specificity - test',\n",
    "                \"Precision - test\", \"Recall - test\", \"F1-score - test\", \"MCC - test\", \"AUC - test\"]\n",
    "if export_content == \"Rankings\":\n",
    "    d6 = dataset[keep_columns].groupby([\"Dimensionality reduction technique\", \"Number of features\"]).mean().sort_values(by=['F1-score - test'], ascending=False)\n",
    "else:\n",
    "    d6 = dataset[keep_columns].groupby([\"Dimensionality reduction technique\", \"Number of features\"]).agg([np.mean, np.std])\n",
    "dataset_list.append(d6.round(2))\n",
    "d6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot dimensionality reduction technique"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keep_columns = [\"Dimensionality reduction technique\", \"Accuracy - test\", 'Specificity - test',\n",
    "                \"Precision - test\", \"Recall - test\", \"F1-score - test\", \"MCC - test\", \"AUC - test\"]\n",
    "if export_content == \"Rankings\":\n",
    "    d7 = dataset[keep_columns].groupby([\"Dimensionality reduction technique\"]).mean().sort_values(by=['F1-score - test'], ascending=False)\n",
    "else:\n",
    "    d7 = dataset[keep_columns].groupby([\"Dimensionality reduction technique\"]).agg([np.mean, np.std])\n",
    "dataset_list.append(d7.round(2))\n",
    "d7"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot imbalanced data technique"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keep_columns = [\"Imbalanced data technique\", \"Accuracy - test\", 'Specificity - test',\n",
    "                \"Precision - test\", \"Recall - test\", \"F1-score - test\", \"MCC - test\", \"AUC - test\"]\n",
    "if export_content == \"Rankings\":\n",
    "    d8 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Imbalanced data technique\"]).mean().sort_values(by=['F1-score - test'], ascending=False)\n",
    "else:\n",
    "    d8 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Imbalanced data technique\"]).agg([np.mean, np.std])\n",
    "dataset_list.append(d8.round(2))\n",
    "d8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = pd.melt(dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], id_vars=['Imbalanced data technique'],\n",
    "                  value_vars=['Accuracy - test', 'Specificity - test', 'Precision - test', 'Recall - test', 'F1-score - test', 'MCC - test', 'AUC - test'],\n",
    "                  var_name='Metric')\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Imbalanced data technique\", y=\"value\", hue=\"Metric\", data=results, orient=\"v\")\n",
    "plt.legend(loc='lower left')\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Imbalanced_data_technique_score_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot Imbalanced data technique & Dataset train/test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keep_columns = [\"Imbalanced data technique\", \"Dataset - train/test\", \"Accuracy - test\", 'Specificity - test',\n",
    "                \"Precision - test\", \"Recall - test\", \"F1-score - test\",  \"MCC - test\", \"AUC - test\"]\n",
    "if export_content == \"Rankings\":\n",
    "    d9 = dataset[keep_columns][dataset[\"Dimensionality reduction technique\"] == \"N.A.\"].groupby([\"Imbalanced data technique\", \"Dataset - train/test\"]).mean().sort_values(by=['F1-score - test'], ascending=False)\n",
    "else:\n",
    "    d9 = dataset[keep_columns][dataset[\"Dimensionality reduction technique\"] == \"N.A.\"].groupby([\"Imbalanced data technique\", \"Dataset - train/test\"]).agg([np.mean, np.std])\n",
    "dataset_list.append(d9.round(2))\n",
    "d9"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot Imbalanced data technique & Model type"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keep_columns = [\"Imbalanced data technique\", \"Model type\", \"Accuracy - test\", 'Specificity - test',\n",
    "                \"Precision - test\", \"Recall - test\", \"F1-score - test\", \"MCC - test\", \"AUC - test\"]\n",
    "if export_content == \"Rankings\":\n",
    "    d10 = dataset[keep_columns][dataset[\"Dimensionality reduction technique\"] == \"N.A.\"].groupby([\"Imbalanced data technique\", \"Model type\"]).mean().sort_values(by=['F1-score - test'], ascending=False)\n",
    "else:\n",
    "    d10 = dataset[keep_columns][dataset[\"Dimensionality reduction technique\"] == \"N.A.\"].groupby([\"Imbalanced data technique\", \"Model type\"]).agg([np.mean, np.std])\n",
    "dataset_list.append(d10.round(2))\n",
    "d10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot model & validation metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keep_columns = [\"Model type\", \"Accuracy - validation\", 'Specificity - validation', \"Precision - validation\",\n",
    "                \"Recall - validation\", \"F1-score - validation\", \"MCC - validation\", \"AUC - validation\"]\n",
    "if export_content == \"Rankings\":\n",
    "    d11 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Model type\"]).mean().sort_values(by=['F1-score - validation'], ascending=False)\n",
    "else:\n",
    "    d11 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Model type\"]).agg([np.mean, np.std])\n",
    "dataset_list.append(d11.round(2))\n",
    "d11"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = pd.melt(dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], id_vars=['Model type'],\n",
    "                  value_vars=['Accuracy - validation', 'Specificity - validation', 'Precision - validation',\n",
    "                              'Recall - validation', 'F1-score - validation',  'MCC - validation', 'AUC - validation'],\n",
    "                  var_name='Metric')\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Model type\", y=\"value\", hue=\"Metric\", data=results, orient=\"v\", order=keys_order)\n",
    "plt.legend(loc='lower left')\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Metrics_validation.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot model & training time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keep_columns = [\"Model type\", \"Training time\"]\n",
    "if export_content == \"Rankings\":\n",
    "    d12 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Model type\"]).mean().sort_values(by=['Training time'], ascending=False)\n",
    "else:\n",
    "    d12 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Model type\"]).agg([np.mean, np.std])\n",
    "dataset_list.append(d12.round(2))\n",
    "d12"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "ax = sns.barplot(x=\"Model type\", y=\"Training time\", data=dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], order=keys_order)\n",
    "ax.set(ylabel='Training time (s)')\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Training_time.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot train/test split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keep_columns = [\"Train/Test split\", \"Accuracy - test\", 'Specificity - test',\n",
    "                \"Precision - test\", \"Recall - test\", \"F1-score - test\", \"MCC - test\", \"AUC - test\"]\n",
    "if export_content == \"Rankings\":\n",
    "    d13 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Train/Test split\"]).mean().sort_values(by=['F1-score - test'], ascending=False)\n",
    "else:\n",
    "    d13 = dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"][keep_columns].groupby([\"Train/Test split\"]).agg([np.mean, np.std])\n",
    "dataset_list.append(d13.round(2))\n",
    "d13"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = pd.melt(dataset[dataset[\"Dimensionality reduction technique\"] == \"N.A.\"], id_vars=['Train/Test split'],\n",
    "                  value_vars=['Accuracy - test', 'Specificity - test', 'Precision - test', 'Recall - test', 'F1-score - test', 'MCC - test', 'AUC - test'],\n",
    "                  var_name='Metric')\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 6))\n",
    "sns.barplot(x=\"Train/Test split\", y=\"value\", hue=\"Metric\", data=results, orient=\"v\")\n",
    "plt.legend(loc='lower left')\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Train_test_split.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot PCA number of components"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selected_dataset = dataset[(dataset['Dimensionality reduction technique'] == \"PCA\")\n",
    "                           & (dataset['Dataset - train/test'] == \"filtered_active_bankruptcy_raw_full_history4_0.pkl\")]\n",
    "# Plot only if not empty\n",
    "if selected_dataset.shape[0] != 0:\n",
    "    sns.set_theme(style=\"white\")\n",
    "    plt.subplots(figsize=(9, 6))\n",
    "    sns.barplot(x=\"Number of features\", y=\"F1-score - test\", hue=\"Model type\", data=selected_dataset, orient=\"v\")\n",
    "    plt.legend(loc='lower left')\n",
    "    if to_export:\n",
    "        plt.savefig(OUTPUT_PATH + \"/Classification_metrics/PCA_num_features_score_test.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot only if not empty\n",
    "if selected_dataset.shape[0] != 0:\n",
    "    # Take each dictionary containing the couples (feature_name, importance)\n",
    "    dict_list = selected_dataset[(selected_dataset[\"Features importance\"] != \"N.A.\")][\"Features importance\"].tolist()\n",
    "\n",
    "    # Create two auxiliary dictionaries\n",
    "    sum = {}\n",
    "    count = {}\n",
    "\n",
    "    # Set all the keys' possible values to 0\n",
    "    # For each dictionary\n",
    "    for dictionary in dict_list:\n",
    "        # For each couple (key, value)\n",
    "        for key, value in dictionary.items():\n",
    "            sum[key] = 0\n",
    "            count[key] = 0\n",
    "\n",
    "    # Increment all the keys based on the dictionaries values\n",
    "    # For each dictionary\n",
    "    for dictionary in dict_list:\n",
    "        # For each couple (key, value)\n",
    "        for key, value in dictionary.items():\n",
    "            sum[key] += value\n",
    "            count[key] += 1\n",
    "\n",
    "    # Create mean dictionary\n",
    "    mean = {}\n",
    "\n",
    "    # Compute mean for each key\n",
    "    for key, value in sum.items():\n",
    "        mean[key] = sum[key] / count[key]\n",
    "\n",
    "    # Order the dictionary by value\n",
    "    ordered_mean = dict(sorted(mean.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    # Take the 20 most important features\n",
    "    keys = list(ordered_mean.keys())[:20]\n",
    "\n",
    "    # Create a list of the 50 most important features values\n",
    "    feature_importance = []\n",
    "    feature_names = []\n",
    "\n",
    "    # For each dictionary\n",
    "    for dictionary in dict_list:\n",
    "        # For each couple (key, value)\n",
    "        for key, value in dictionary.items():\n",
    "            # If one of the 50 most important features\n",
    "            if key in keys:\n",
    "                feature_names.append(key)\n",
    "                feature_importance.append(value)\n",
    "\n",
    "\n",
    "    # Plot the results\n",
    "    sns.set_theme(style=\"white\")\n",
    "    plt.subplots(figsize=(9, 5))\n",
    "    ax = sns.barplot(x=feature_importance, y=feature_names, order=keys)\n",
    "    ax.set(xlabel='Component importance')\n",
    "\n",
    "    if to_export:\n",
    "        plt.savefig(OUTPUT_PATH + \"/Classification_metrics/PCA_component_importance.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot feature importance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Take each dictionary containing the couples (feature_name, importance)\n",
    "dict_list = dataset[(dataset[\"Features importance\"] != \"N.A.\") & (dataset[\"Dimensionality reduction technique\"] == \"N.A.\")][\"Features importance\"].tolist()\n",
    "\n",
    "# Create two auxiliary dictionaries\n",
    "sum = {}\n",
    "count = {}\n",
    "\n",
    "# Set all the keys' possible values to 0\n",
    "# For each dictionary\n",
    "for dictionary in dict_list:\n",
    "    # For each couple (key, value)\n",
    "    for key, value in dictionary.items():\n",
    "        sum[key] = 0\n",
    "        count[key] = 0\n",
    "\n",
    "# Increment all the keys based on the dictionaries values\n",
    "# For each dictionary\n",
    "for dictionary in dict_list:\n",
    "    # For each couple (key, value)\n",
    "    for key, value in dictionary.items():\n",
    "        sum[key] += value\n",
    "        count[key] += 1\n",
    "\n",
    "# Create mean dictionary\n",
    "mean = {}\n",
    "\n",
    "# Compute mean for each key\n",
    "for key, value in sum.items():\n",
    "    mean[key] = sum[key] / count[key]\n",
    "\n",
    "# Order the dictionary by value\n",
    "ordered_mean = dict(sorted(mean.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Take the 50 most important features\n",
    "keys = list(ordered_mean.keys())[:50]\n",
    "\n",
    "# Create a list of the 50 most important features values\n",
    "feature_importance = []\n",
    "feature_names = []\n",
    "\n",
    "# For each dictionary\n",
    "for dictionary in dict_list:\n",
    "    # For each couple (key, value)\n",
    "    for key, value in dictionary.items():\n",
    "        # If one of the 50 most important features\n",
    "        if key in keys:\n",
    "            feature_names.append(key)\n",
    "            feature_importance.append(value)\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 15))\n",
    "ax = sns.barplot(x=feature_importance, y=feature_names, order=keys)\n",
    "ax.set(xlabel='Feature importance')\n",
    "\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Feature_importance.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_dataset = pd.DataFrame()\n",
    "feature_dataset[\"Feature name\"] = feature_names\n",
    "feature_dataset[\"Feature importance\"] = feature_importance\n",
    "if export_content == \"Rankings\":\n",
    "    d14 = feature_dataset.groupby([\"Feature name\"]).mean().sort_values(by=['Feature importance'], ascending=False)\n",
    "else:\n",
    "    d14 = feature_dataset.groupby([\"Feature name\"]).agg([np.mean, np.std]).sort_values(by=[('Feature importance', 'mean')], ascending=False)\n",
    "dataset_list.append(d14.round(2))\n",
    "d14"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot feature importance financial estimators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Collect only the financial estimators names\n",
    "financial_estimator_names_regex = \"PN/TOTALE DEBITI*|DEB. PREV \\+ TRIB/ATTIVO*|TEMPO MEDIO RISCOSSIONE \\(TMR\\)*|TEMPO MEDIO DI PAGAMENTO \\(TMP\\)|\" \\\n",
    "                                  \"PFN\\/EBITDA*|PFN\\/PN*|GEARING*|ROS*|WORKING CAPITAL\\/NET SALES*|CASH\\/CURRENT LIABILITIES*|\" \\\n",
    "                                  \"ACCOUNTS RECEIVABLE\\/INVENTORY*|EBIT\\/INTEREST EXPENSES*|ATT.BR\\/ATTIVO*|RICAVI\\/ATTIVO*|EBITDA\\/TOTALE DEBITI*\"\n",
    "r = re.compile(financial_estimator_names_regex, re.IGNORECASE)\n",
    "financial_estimator_keys = list(filter(r.match, ordered_mean.keys()))\n",
    "\n",
    "\n",
    "# Create dictionary feature name: feature value mean\n",
    "financial_estimator_dictionary = {}\n",
    "\n",
    "# For each dictionary\n",
    "for dictionary in dict_list:\n",
    "    # For each couple (key, value)\n",
    "    for key, value in ordered_mean.items():\n",
    "        # If the key is a financial estimator\n",
    "        if key in financial_estimator_keys:\n",
    "            financial_estimator_dictionary[key] = value\n",
    "\n",
    "# Order by feature importance\n",
    "financial_estimator_dictionary = dict(sorted(financial_estimator_dictionary.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Collect all value to plot mean and expected value range\n",
    "financial_estimator_feature_importance = []\n",
    "financial_estimator_feature_names = []\n",
    "\n",
    "# For each dictionary\n",
    "for dictionary in dict_list:\n",
    "    # For each couple (key, value)\n",
    "    for key, value in dictionary.items():\n",
    "        # If the key is a financial estimator\n",
    "        if key in financial_estimator_keys:\n",
    "            financial_estimator_feature_names.append(key)\n",
    "            financial_estimator_feature_importance.append(value)\n",
    "\n",
    "# Plot the results\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 15))\n",
    "ax = sns.barplot(x=financial_estimator_feature_importance, y=financial_estimator_feature_names, order=financial_estimator_dictionary.keys())\n",
    "ax.set(xlabel='Feature importance')\n",
    "\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Financial_estimator_importance.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "financial_estimator_feature_dataset = pd.DataFrame()\n",
    "financial_estimator_feature_dataset[\"Feature name\"] = financial_estimator_feature_names\n",
    "financial_estimator_feature_dataset[\"Feature importance\"] = financial_estimator_feature_importance\n",
    "if export_content == \"Rankings\":\n",
    "    d15 = financial_estimator_feature_dataset.groupby([\"Feature name\"]).mean().sort_values(by=['Feature importance'], ascending=False)\n",
    "else:\n",
    "    d15 = financial_estimator_feature_dataset.groupby([\"Feature name\"]).agg([np.mean, np.std])\\\n",
    "        .sort_values(by=[('Feature importance', 'mean')], ascending=False)\n",
    "dataset_list.append(d15.round(2))\n",
    "d15"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot feature importance raw values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create dictionary feature name: feature value mean\n",
    "raw_values_dictionary = {}\n",
    "\n",
    "# For each dictionary\n",
    "for dictionary in dict_list:\n",
    "    # For each couple (key, value)\n",
    "    for key, value in ordered_mean.items():\n",
    "        # If the key is a raw value\n",
    "        if key not in financial_estimator_keys:\n",
    "            raw_values_dictionary[key] = value\n",
    "\n",
    "# Order by feature importance\n",
    "raw_values_dictionary = dict(sorted(raw_values_dictionary.items(), key=lambda item: item[1], reverse=True))\n",
    "raw_values_top_keys = list(raw_values_dictionary.keys())[:50]\n",
    "\n",
    "# Collect all value to plot mean and expected value range\n",
    "raw_values_feature_importance = []\n",
    "raw_values_feature_names = []\n",
    "\n",
    "# For each dictionary\n",
    "for dictionary in dict_list:\n",
    "    # For each couple (key, value)\n",
    "    for key, value in dictionary.items():\n",
    "        # If the key is a raw value\n",
    "        if key in raw_values_top_keys:\n",
    "            raw_values_feature_names.append(key)\n",
    "            raw_values_feature_importance.append(value)\n",
    "\n",
    "# Plot the results\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.subplots(figsize=(9, 15))\n",
    "ax = sns.barplot(x=raw_values_feature_importance, y=raw_values_feature_names, order=raw_values_top_keys)\n",
    "ax.set(xlabel='Feature importance')\n",
    "\n",
    "if to_export:\n",
    "    plt.savefig(OUTPUT_PATH + \"/Classification_metrics/Raw_values_importance.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot model type, unbalanced technique, train/test split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keep_columns = [\"Model type\", \"Imbalanced data technique\", \"Dataset - train/test\", \"Accuracy - test\", 'Specificity - test',\n",
    "                \"Precision - test\", \"Recall - test\", \"F1-score - test\",  \"MCC - test\", \"AUC - test\"]\n",
    "if export_content == \"Rankings\":\n",
    "    d16 = dataset[keep_columns].groupby([\"Model type\", \"Imbalanced data technique\", \"Dataset - train/test\"]).mean().sort_values(by=['F1-score - test'], ascending=False)\n",
    "else:\n",
    "    d16 = dataset[keep_columns].groupby([\"Model type\", \"Imbalanced data technique\", \"Dataset - train/test\"]).agg([np.mean, np.std])\n",
    "dataset_list.append(d16.round(2))\n",
    "d16"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esporto in formato xlsx se richiesto"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function in order to generate a unique excel file with multiple sheets\n",
    "# from multiple pandas datasets\n",
    "def save_xls(list_dfs, xls_path, na_replace):\n",
    "    with ExcelWriter(xls_path, engine=\"xlsxwriter\") as writer:\n",
    "        for n, df in enumerate(list_dfs):\n",
    "            if na_replace:\n",
    "                df.to_excel(writer, 'sheet%s' % n, na_rep=\"N.A.\")\n",
    "            else:\n",
    "                df.to_excel(writer, 'sheet%s' % n)\n",
    "            writer.sheets[\"sheet\"+str(n)].set_column(0, 10, 35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if to_export:\n",
    "    # Experiments dataset\n",
    "    dataset.to_excel(OUTPUT_PATH + \"/ML_model_experiments.xlsx\", engine='xlsxwriter')\n",
    "    if export_content == \"Rankings\":\n",
    "        na_rep = True\n",
    "    else:\n",
    "        na_rep = False\n",
    "    # Rankings/Description datasets\n",
    "    save_xls(dataset_list, OUTPUT_PATH + \"/\" + export_content.lower() + \".xlsx\", na_replace=na_rep)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
