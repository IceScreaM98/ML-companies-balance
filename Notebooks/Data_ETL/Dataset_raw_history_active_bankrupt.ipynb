{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Complete dataset (active + bankrupt) focused on raw financial values and their history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Librerie varie da installare"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install matplotlib\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inclusione delle librerie utilizzate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Variabili di gestione files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Path of the files, can be changed\n",
    "PATH_ACTIVE_DATASET = r\"C:\\Users\\Andre\\OneDrive - Università degli Studi di Parma\\Tirocinio\\Dataset_output\\active_raw_history.pkl\"\n",
    "\n",
    "PATH_BANKRUPT_DATASET = r\"C:\\Users\\Andre\\OneDrive - Università degli Studi di Parma\\Tirocinio\\Dataset_output\\bankruptcy_raw_history.pkl\"\n",
    "\n",
    "# True = export summary file in the OUTPUT_PATH\n",
    "to_export = True\n",
    "\n",
    "# Specify the strength of the quantile data filtering, recommended between 0.05 and 0.25\n",
    "quantile_amount = 0.05\n",
    "\n",
    "# True = replace missing value and use all the 4 years, False = keep n year and remove the records with missing values\n",
    "replace_na_value = False\n",
    "\n",
    "# Number of year to be kept (between 2 and 4)\n",
    "keep_n_year = 4\n",
    "\n",
    "# Path of the desired output file, can be changed\n",
    "OUTPUT_PATH = r\"C:\\Users\\Andre\\OneDrive - Università degli Studi di Parma\\Tirocinio\\Dataset_output\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Leggo il dataset composto dai 2 file pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "active_dataset = pd.read_pickle(PATH_ACTIVE_DATASET)\n",
    "bankrupt_dataset = pd.read_pickle(PATH_BANKRUPT_DATASET)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unisco i 2 dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "complete_dataset = pd.concat([active_dataset, bankrupt_dataset])\n",
    "complete_dataset.reset_index(inplace=True)\n",
    "complete_dataset.drop(columns=\"index\", axis=1, inplace=True)\n",
    "# Remove excessive descriptive columns\n",
    "complete_dataset.drop(columns=[\"Ragione sociale\", \"Province\", \"Vat number\", \"Accounting closing date\", \"Company Size\", \"Legal Form\"], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tengo traccia dello storico dei vari bilanci per la medesima impresa in unico record"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "complete_dataset = complete_dataset.set_index([\"Tax code number\", \"CCIAA number\", \"Legal Status\",\n",
    "                                               complete_dataset.groupby([\"Tax code number\", \"CCIAA number\", \"Legal Status\"]).cumcount()+1]).unstack().sort_index(level=1, axis=1)\n",
    "complete_dataset.columns = complete_dataset.columns.map('{0[0]}_{0[1]}'.format)\n",
    "complete_dataset.reset_index(inplace=True)\n",
    "complete_dataset.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(complete_dataset.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gestisco il dataset in base a come gestire i valori mancanti"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if replace_na_value:\n",
    "    complete_dataset.fillna(0.0, inplace=True)\n",
    "else:\n",
    "    start_year = 2\n",
    "    # Remove NA from the first n years\n",
    "    while start_year <= keep_n_year:\n",
    "        year_cols = complete_dataset.filter(regex=(\"_\"+str(start_year)+\"$\"), axis=1).columns\n",
    "        complete_dataset.dropna(subset = year_cols, inplace=True)\n",
    "        start_year += 1\n",
    "    # Drop columns of the last n years, if available\n",
    "    if start_year <= 4:\n",
    "        while start_year <= 4:\n",
    "            year_cols = complete_dataset.filter(regex=(\"_\"+str(start_year)+\"$\"), axis=1).columns\n",
    "            complete_dataset.drop(columns=year_cols, axis=1, inplace=True)\n",
    "            start_year += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Analizzo il dataset completo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%0.4f' % x)\n",
    "complete_dataset.describe().T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esporto in csv e pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if to_export:\n",
    "    dataset_name = \"complete_active_bankruptcy_raw_history\"\n",
    "\n",
    "    if not replace_na_value:\n",
    "        dataset_name += str(keep_n_year)\n",
    "\n",
    "    complete_dataset.to_csv(OUTPUT_PATH + \"/\" + dataset_name + \".csv\")\n",
    "    complete_dataset.to_pickle(OUTPUT_PATH + \"/\" + dataset_name + \".pkl\")\n",
    "    print(\"Dataset\", dataset_name, \"esportato\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rimuovo possibili outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filtered_dataset = pd.DataFrame()\n",
    "# Do the following steps for each feature\n",
    "for index_col in complete_dataset.columns:\n",
    "    # Only numeric columns\n",
    "    if np.issubdtype(complete_dataset[index_col].dtype , np.number):\n",
    "        # Compute the first and third quartile\n",
    "        Q1 = complete_dataset[index_col].quantile(quantile_amount)\n",
    "        Q3 = complete_dataset[index_col].quantile(1 - quantile_amount)\n",
    "        # The intermediate quantile value is the difference between the third and the first one\n",
    "        IQR = Q3 - Q1\n",
    "        # The two bounds: lower and upper bound are computed\n",
    "        MIN = Q1 - 1.5 * IQR\n",
    "        MAX = Q1 + 1.5 * IQR\n",
    "        # Remove the records outside the range [lowerbound, upperbound]\n",
    "        filtered_dataset = complete_dataset[(complete_dataset[index_col] >= MIN) & (complete_dataset[index_col] <= MAX)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esporto in csv e pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if to_export:\n",
    "    filtered_dataset_name = dataset_name.replace(\"complete\", \"filtered\")\n",
    "    discarded_percentage = round(100 - filtered_dataset.shape[0] / complete_dataset.shape[0] * 100)\n",
    "    filtered_dataset.to_csv(OUTPUT_PATH + \"/\" + filtered_dataset_name + \"_\" + str(discarded_percentage) + \".csv\")\n",
    "    filtered_dataset.to_pickle(OUTPUT_PATH + \"/\" + filtered_dataset_name + \"_\" + str(discarded_percentage) + \".pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}